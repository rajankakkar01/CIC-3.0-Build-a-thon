{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvL5hBPYOgN5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'kittiroadsegmentation:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1668350%2F2736560%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240327%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240327T140431Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2c7687cb153e54eda187ac8454cc9616e5c0502cd4abd82c57630042740b5453469f82b35891e0590c586dc1ba96c79c9c7440af1dfe0662a1015626d2fe59bea676dc158850d82892a22d2261ec06c3c6536c68f186b95c265546e974acab6961f3c61ab024dbc63146fdfe432bb179c6c579bcbb06e45446e302d826f3dba836db2346e09ffab80462293d7f591c5fb91697efb2766d5e77717677eb9b796cb25321c22ca229a86d27974b4dc777732cfc71b328a1dbafbe1a0246c7e14289b4af599356c1874c9c889562ca57edd3650c7d02ae88223c2ec95af1b5051ef77d7c7a32f0039dd7e4092ab011c3b2a4f4dbc8fe35ac35f07432a47e94ece371'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufn9z_7HOgN8"
      },
      "source": [
        "# Fully Convolutional Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3fT2IH5OgN-"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T04:52:29.348748Z",
          "iopub.status.busy": "2021-10-26T04:52:29.348177Z",
          "iopub.status.idle": "2021-10-26T04:52:29.372591Z",
          "shell.execute_reply": "2021-10-26T04:52:29.371925Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.348703Z"
        },
        "id": "E95EJJiGOgN-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
        "from tensorflow.keras.layers import Input, Add, Conv2DTranspose\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanSquaredError, BinaryCrossentropy\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import callbacks\n",
        "\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from IPython.display import clear_output\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_mfdc3sOgN-"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3hYwMGyOgN_"
      },
      "source": [
        "### Source Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T04:52:29.374809Z",
          "iopub.status.busy": "2021-10-26T04:52:29.374385Z",
          "iopub.status.idle": "2021-10-26T04:52:29.385296Z",
          "shell.execute_reply": "2021-10-26T04:52:29.384627Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.374772Z"
        },
        "id": "0x8INmxOOgN_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load directories\n",
        "train_data_dir = \"../input/kittiroadsegmentation/training/image_2/\"\n",
        "train_gt_dir = \"../input/kittiroadsegmentation/training/gt_image_2/\"\n",
        "\n",
        "test_data_dir = \"../input/kittiroadsegmentation/testing/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T04:52:29.386865Z",
          "iopub.status.busy": "2021-10-26T04:52:29.386567Z",
          "iopub.status.idle": "2021-10-26T04:52:29.397555Z",
          "shell.execute_reply": "2021-10-26T04:52:29.396473Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.386831Z"
        },
        "id": "LM5-5uSlOgOA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#DATASET SPLITING\n",
        "TRAINSET_SIZE = int(len(os.listdir(train_data_dir)) * 0.8)\n",
        "print(f\"Number of Training Examples: {TRAINSET_SIZE}\")\n",
        "\n",
        "VALIDSET_SIZE = int(len(os.listdir(train_data_dir)) * 0.1)\n",
        "print(f\"Number of Validation Examples: {VALIDSET_SIZE}\")\n",
        "\n",
        "TESTSET_SIZE = int(len(os.listdir(train_data_dir)) - TRAINSET_SIZE - VALIDSET_SIZE)\n",
        "print(f\"Number of Testing Examples: {TESTSET_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T04:52:29.400285Z",
          "iopub.status.busy": "2021-10-26T04:52:29.399573Z",
          "iopub.status.idle": "2021-10-26T04:52:29.406405Z",
          "shell.execute_reply": "2021-10-26T04:52:29.405212Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.40025Z"
        },
        "id": "_GYeDiGDOgOA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Constant for image Processing and model training\n",
        "IMG_SIZE = 128          #Size of image for processing\n",
        "N_CHANNELS = 3          #Number of color channel int the image(RGB)\n",
        "N_CLASSES = 1           #Number of output classes(for classification task)\n",
        "SEED = 123              #Seed for random number generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T04:52:29.40845Z",
          "iopub.status.busy": "2021-10-26T04:52:29.407639Z",
          "iopub.status.idle": "2021-10-26T04:52:29.429158Z",
          "shell.execute_reply": "2021-10-26T04:52:29.428492Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.408414Z"
        },
        "id": "b8kI8dv2OgOB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to load an image and its corresponding segmentation mask\n",
        "def parse_image(img_path: str) -> dict:\n",
        "    # Read image file\n",
        "    image = tf.io.read_file(img_path)\n",
        "    # Decode JPEG image\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    # Convert image to uint8 data type\n",
        "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "\n",
        "    # Define the path for the segmentation task\n",
        "    mask_path = tf.strings.regex_replace(img_path, \"image_2\", \"gt_image_2\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"um_\", \"um_road_\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"umm_\", \"umm_road_\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"uu_\", \"uu_road_\")\n",
        "    \n",
        "    # Read segmentation task \n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    # Decode PNG mask\n",
        "    mask = tf.image.decode_png(mask, channels=3)\n",
        "\n",
        "    # Define label colors\n",
        "    non_road_label = np.array([255, 0, 0])\n",
        "    road_label = np.array([255, 0, 255])\n",
        "    other_road_label = np.array([0, 0, 0])\n",
        "\n",
        "    # Convert segmentation mask to binary mask\n",
        "    mask = tf.experimental.numpy.all(mask == road_label, axis = 2)\n",
        "    mask = tf.cast(mask, tf.uint8)\n",
        "    mask = tf.expand_dims(mask, axis=-1)\n",
        "    # Return a dictionary containing the image and its segmentation mask\n",
        "    return {'image': image, 'segmentation_mask': mask}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T04:52:29.433517Z",
          "iopub.status.busy": "2021-10-26T04:52:29.431835Z",
          "iopub.status.idle": "2021-10-26T04:52:29.510632Z",
          "shell.execute_reply": "2021-10-26T04:52:29.509767Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.433479Z"
        },
        "id": "6NdxP0-_OgOB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Generate dataset variables\n",
        "# Create a dataset containing file paths to all image files in the training data directory\n",
        "all_dataset = tf.data.Dataset.list_files(train_data_dir + \"*.png\", seed=SEED)\n",
        "# Apply the parse_image fxn to each file path to load images and their corresponding segmentation mask\n",
        "all_dataset = all_dataset.map(parse_image)\n",
        "\n",
        "# split the dataset into training, validation, and test sets\n",
        "# combine the training and validation dataset\n",
        "train_dataset = all_dataset.take(TRAINSET_SIZE + VALIDSET_SIZE)\n",
        "# Skip the first TRAINSET_SIZE elements to obtain the validation dataset\n",
        "val_dataset = train_dataset.skip(TRAINSET_SIZE)\n",
        "# Take only the first TRAINSET_SIZE elements to obtain the final training dataset\n",
        "train_dataset = train_dataset.take(TRAINSET_SIZE)\n",
        "# Skip the training and validation data to obtain the test dataset\n",
        "test_dataset = all_dataset.skip(TRAINSET_SIZE + VALIDSET_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2xlhxH-OgOB"
      },
      "source": [
        "### Apply Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T04:52:29.517226Z",
          "iopub.status.busy": "2021-10-26T04:52:29.515206Z",
          "iopub.status.idle": "2021-10-26T04:52:29.531209Z",
          "shell.execute_reply": "2021-10-26T04:52:29.530443Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.517182Z"
        },
        "id": "tzgJ7LbKOgOB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Tensorflow function to normalize imput images and mask to range [0,1]\n",
        "@tf.function\n",
        "def normalize(input_image: tf.Tensor, input_mask: tf.Tensor) -> tuple:\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    return input_image, input_mask\n",
        "\n",
        "# Tensorflow function to preprocess image for training\n",
        "@tf.function\n",
        "def load_image_train(datapoint: dict) -> tuple:\n",
        "    # Resize input image and mask to specified dimentions\n",
        "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
        "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
        "    \n",
        "    # Randomly flip the image and mask horizontally with a probablity of 50%\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "    # Normalize input image and mask\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "    return input_image, input_mask\n",
        "\n",
        "# Tensorflow function to preprocess images for validation/testing\n",
        "@tf.function\n",
        "def load_image_test(datapoint: dict) -> tuple:\n",
        "    # Resize input image and mask to specified dimentions\n",
        "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
        "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
        "    \n",
        "    # Normalize input image and mask\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "    return input_image, input_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T04:52:29.536432Z",
          "iopub.status.busy": "2021-10-26T04:52:29.53604Z",
          "iopub.status.idle": "2021-10-26T04:52:29.739158Z",
          "shell.execute_reply": "2021-10-26T04:52:29.738374Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.536397Z"
        },
        "id": "EiRSgR7QOgOC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32     #Number of samples per batch\n",
        "BUFFER_SIZE = 1000  #Buffer size for shuffling dataset\n",
        "\n",
        "# Combine datasets for training, validation and testing\n",
        "dataset = {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset}\n",
        "\n",
        "# Preprocess and configure the training dataset\n",
        "# Training dataset transformation: load, shuffle, batch and prefetch\n",
        "dataset['train'] = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset['train'] = dataset['train'].shuffle(buffer_size=BUFFER_SIZE, seed=SEED)\n",
        "dataset['train'] = dataset['train'].batch(BATCH_SIZE)\n",
        "dataset['train'] = dataset['train'].prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Preprocess and configure the validation dataset\n",
        "# Validation dataset transformations: load, batch and prefetch\n",
        "dataset['val'] = dataset['val'].map(load_image_test)\n",
        "dataset['val'] = dataset['val'].batch(BATCH_SIZE)\n",
        "dataset['val'] = dataset['val'].prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Preprocess and configure the testing dataset\n",
        "# Testing dataset transformations: load, batch and prefetch\n",
        "dataset['test'] = dataset['test'].map(load_image_test)\n",
        "dataset['test'] = dataset['test'].batch(BATCH_SIZE)\n",
        "dataset['test'] = dataset['test'].prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Display information about each dataset\n",
        "print(dataset['train'])\n",
        "print(dataset['val'])\n",
        "print(dataset['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T04:52:29.740945Z",
          "iopub.status.busy": "2021-10-26T04:52:29.740478Z",
          "iopub.status.idle": "2021-10-26T04:52:43.209188Z",
          "shell.execute_reply": "2021-10-26T04:52:43.208439Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.740906Z"
        },
        "id": "QpBlA1S8OgOC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to display sample images and mask\n",
        "def display_sample(display_list):\n",
        "    # Create a figure to display images and masks\n",
        "    plt.figure(figsize=(18, 18))\n",
        "\n",
        "    # Titles for different components of the display\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "    # Iterate over the display list \n",
        "    for i in range(len(display_list)):\n",
        "        # Add a subplot for each component\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        # set title for the subplot\n",
        "        plt.title(title[i])\n",
        "        # Display the image/mask usng array_to_img method\n",
        "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "        # Turf off axis labels\n",
        "        plt.axis('off')\n",
        "\n",
        "    # Show the figure with the images and mask\n",
        "    plt.show()\n",
        "\n",
        "# Retrive a sample image and mask from the training dataset\n",
        "for image, mask in dataset[\"train\"].take(1):\n",
        "    sample_image, sample_mask = image, mask\n",
        "# Display the sample image and mask\n",
        "display_sample([sample_image[0], sample_mask[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am8GUQBJOgOC"
      },
      "source": [
        "## Define Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T04:52:43.211272Z",
          "iopub.status.busy": "2021-10-26T04:52:43.210755Z",
          "iopub.status.idle": "2021-10-26T04:52:45.09499Z",
          "shell.execute_reply": "2021-10-26T04:52:45.09423Z",
          "shell.execute_reply.started": "2021-10-26T04:52:43.211235Z"
        },
        "id": "LwMLcJb5OgOC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load the VGG_16 network as a backbone\n",
        "vgg16_model = VGG16()\n",
        "# Display summary of the VGG-16 model\n",
        "vgg16_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T04:52:45.096464Z",
          "iopub.status.busy": "2021-10-26T04:52:45.096221Z",
          "iopub.status.idle": "2021-10-26T04:52:45.102926Z",
          "shell.execute_reply": "2021-10-26T04:52:45.102089Z",
          "shell.execute_reply.started": "2021-10-26T04:52:45.096431Z"
        },
        "id": "1yaFtezEOgOC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define the input shape for the model\n",
        "input_shape = (IMG_SIZE, IMG_SIZE, N_CHANNELS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T05:19:55.957134Z",
          "iopub.status.busy": "2021-10-26T05:19:55.956499Z",
          "iopub.status.idle": "2021-10-26T05:19:56.291184Z",
          "shell.execute_reply": "2021-10-26T05:19:56.290407Z",
          "shell.execute_reply.started": "2021-10-26T05:19:55.957093Z"
        },
        "id": "GEMOt7UtOgOC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Generate a new model using the VGG network as a network\n",
        "\n",
        "# Input layer\n",
        "inputs = Input(input_shape)\n",
        "\n",
        "# Load VGG network without its top layer\n",
        "vgg16_model = VGG16(include_top = False, weights = 'imagenet', input_tensor = inputs)\n",
        "\n",
        "# Define encode layers\n",
        "c1 = vgg16_model.get_layer(\"block3_pool\").output\n",
        "c2 = vgg16_model.get_layer(\"block4_pool\").output\n",
        "c3 = vgg16_model.get_layer(\"block5_pool\").output\n",
        "\n",
        "# Unsampling and concatenation for decoder\n",
        "u1 = UpSampling2D((2, 2), interpolation = 'bilinear')(c3)\n",
        "d1 = Concatenate()([u1, c2])\n",
        "\n",
        "u2 = UpSampling2D((2, 2), interpolation = 'bilinear')(d1)\n",
        "d2 = Concatenate()([u2, c1])\n",
        "\n",
        "# Output layer\n",
        "u3 = UpSampling2D((8, 8), interpolation = 'bilinear')(d2)\n",
        "outputs = Conv2D(N_CLASSES, 1, activation = 'sigmoid')(u3)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs, outputs, name = \"VGG_FCN8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lxXTclAOgOD"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKJFKzLsOgOD"
      },
      "source": [
        "### Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T05:19:59.95255Z",
          "iopub.status.busy": "2021-10-26T05:19:59.951931Z",
          "iopub.status.idle": "2021-10-26T05:19:59.965874Z",
          "shell.execute_reply": "2021-10-26T05:19:59.965013Z",
          "shell.execute_reply.started": "2021-10-26T05:19:59.952513Z"
        },
        "id": "pjSQsopHOgOD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Compile the model with Adam Optimizer, binary-cross entropy loss, and mean Intersection over Union(mIOU) metric\n",
        "m_iou = tf.keras.metrics.MeanIoU(2)\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss=BinaryCrossentropy(),\n",
        "              metrics=[m_iou])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cr0tHhEOgOD"
      },
      "source": [
        "### Check Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T04:52:45.449438Z",
          "iopub.status.busy": "2021-10-26T04:52:45.449024Z",
          "iopub.status.idle": "2021-10-26T04:52:58.403903Z",
          "shell.execute_reply": "2021-10-26T04:52:58.403252Z",
          "shell.execute_reply.started": "2021-10-26T04:52:45.449403Z"
        },
        "id": "ooyK_rHrOgOD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to create a binary mask from network prediction\n",
        "def create_mask(pred_mask: tf.Tensor) -> tf.Tensor:\n",
        "    # Round predicted probablities to the nearest integer(0 or 1)\n",
        "    pred_mask = tf.math.round(pred_mask)\n",
        "\n",
        "    # Expand dimenitons to match the expected shape([IMG_SIZE], IMG_SIZE,1)\n",
        "    pred_mask = tf.expand_dims(pred_mask, axis=-1)\n",
        "    return pred_mask\n",
        "\n",
        "# Function to visualize predictions\n",
        "def show_predictions(dataset=None, num=1):\n",
        "    if dataset:\n",
        "        # Predict and display images from the input dataset\n",
        "        for image, mask in dataset.take(num):\n",
        "            # Generate predicted mask \n",
        "            pred_mask = model.predict(image)\n",
        "            # Display input image, true mask, and predicted mask\n",
        "            display_sample([image[0], true_mask, create_mask(pred_mask)])\n",
        "    else:\n",
        "        # Predict anddisplay a sample image\n",
        "        inference = model.predict(sample_image)\n",
        "        # Display sample input image, true mask, and predicted mask\n",
        "        display_sample([sample_image[0], sample_mask[0],\n",
        "                        inference[0]])\n",
        "\n",
        "# Retrive a sample image and mask from the training dataset\n",
        "for image, mask in dataset['train'].take(1):\n",
        "    sample_image, sample_mask = image, mask\n",
        "\n",
        "# show predictions based on the sample image\n",
        "show_predictions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDKpgYavOgOD"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T04:52:58.405497Z",
          "iopub.status.busy": "2021-10-26T04:52:58.405101Z",
          "iopub.status.idle": "2021-10-26T04:52:58.711714Z",
          "shell.execute_reply": "2021-10-26T04:52:58.710973Z",
          "shell.execute_reply.started": "2021-10-26T04:52:58.40545Z"
        },
        "id": "oIZVE3lnOgOD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Custom callback for displaying sample predictions at the end of each epoch\n",
        "class DisplayCallback(callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Clear the previous output\n",
        "        clear_output(wait=True)\n",
        "        # Show sample predictions\n",
        "        show_predictions()\n",
        "        # Print a mssg indicating sample predictions after the current path\n",
        "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
        "\n",
        "# Define the log directory for TensorBoard\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iozg4IU4UqQ0"
      },
      "outputs": [],
      "source": [
        "# list of callback for training the model\n",
        "callbacks = [\n",
        "    # Custom callback to display sample predictions at the end of each epoch\n",
        "    DisplayCallback(),\n",
        "    # TensorBoard callback for logging training metrics and visualizations\n",
        "    callbacks.TensorBoard(logdir, histogram_freq = -1),\n",
        "    # Early stopping callback to prevent overfitting by stopping training when the validation loss stops improving\n",
        "    callbacks.EarlyStopping(patience = 20, verbose = 1),\n",
        "    # # Model checkpoint callback to save the best model based on validation loss\n",
        "    callbacks.ModelCheckpoint('best_model.h5', verbose = 1, save_best_only = True)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxfG8g1zUqpU"
      },
      "outputs": [],
      "source": [
        "# Set Variables\n",
        "EPOCHS = 100\n",
        "STEPS_PER_EPOCH = TRAINSET_SIZE // BATCH_SIZE\n",
        "VALIDATION_STEPS = VALIDSET_SIZE // BATCH_SIZE\n",
        "print(STEPS_PER_EPOCH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_qOMSgjRPSl"
      },
      "outputs": [],
      "source": [
        "print(STEPS_PER_EPOCH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T05:30:29.766306Z",
          "iopub.status.busy": "2021-10-26T05:30:29.765658Z",
          "iopub.status.idle": "2021-10-26T05:34:19.711077Z",
          "shell.execute_reply": "2021-10-26T05:34:19.707464Z",
          "shell.execute_reply.started": "2021-10-26T05:30:29.766267Z"
        },
        "id": "SnjK_rNpOgOD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_history = model.fit(dataset['train'], epochs=EPOCHS,\n",
        "                          validation_data = dataset[\"val\"],\n",
        "                          callbacks = callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u6heZ7KOgOD"
      },
      "source": [
        "## Testing (Test Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T05:04:21.598023Z",
          "iopub.status.busy": "2021-10-26T05:04:21.597804Z",
          "iopub.status.idle": "2021-10-26T05:04:21.608255Z",
          "shell.execute_reply": "2021-10-26T05:04:21.607477Z",
          "shell.execute_reply.started": "2021-10-26T05:04:21.597997Z"
        },
        "id": "gDY_5qRvOgOE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to calculate mask over image\n",
        "def weighted_img(img, initial_img, α=1., β=0.5, γ=0.):\n",
        "    return cv2.addWeighted(initial_img, α, img, β, γ)\n",
        "\n",
        "# Function to process an individual image and it's mask\n",
        "def process_image_mask(image, mask):\n",
        "    # Round to closest\n",
        "    mask = tf.math.round(mask)\n",
        "\n",
        "    # Convert to mask image\n",
        "    zero_image = np.zeros_like(mask)\n",
        "    mask = np.dstack((mask, zero_image, zero_image))\n",
        "    mask = np.asarray(mask, np.float32)\n",
        "\n",
        "    # Convert to image image\n",
        "    image = np.asarray(image, np.float32)\n",
        "\n",
        "    # Get the final image\n",
        "    final_image = weighted_img(mask, image)\n",
        "\n",
        "    return final_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T05:04:21.610271Z",
          "iopub.status.busy": "2021-10-26T05:04:21.609453Z",
          "iopub.status.idle": "2021-10-26T05:04:21.619483Z",
          "shell.execute_reply": "2021-10-26T05:04:21.618556Z",
          "shell.execute_reply.started": "2021-10-26T05:04:21.610245Z"
        },
        "id": "jTFsO1PjOgOE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to save predictions\n",
        "def save_predictions(dataset):\n",
        "    # Predict and save image the from input dataset\n",
        "    index = 0\n",
        "    for batch_image, batch_mask in dataset:\n",
        "        for image, mask in zip(batch_image, batch_mask):\n",
        "            print(f\"Processing image : {index}\")\n",
        "            pred_mask = model.predict(tf.expand_dims(image, axis = 0))\n",
        "            save_sample([image, process_image_mask(image, pred_mask[0])], index)\n",
        "            index += 1\n",
        "\n",
        "# Function to save the images as a plot\n",
        "def save_sample(display_list, index):\n",
        "    plt.figure(figsize=(18, 18))\n",
        "\n",
        "    title = ['Input Image', 'Predicted Mask']\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig(f\"outputs/{index}.png\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T05:04:21.620971Z",
          "iopub.status.busy": "2021-10-26T05:04:21.620659Z",
          "iopub.status.idle": "2021-10-26T05:04:38.614623Z",
          "shell.execute_reply": "2021-10-26T05:04:38.613957Z",
          "shell.execute_reply.started": "2021-10-26T05:04:21.620936Z"
        },
        "id": "NfQ62VGtOgOE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# os.mkdir(\"outputs\")\n",
        "save_predictions(dataset['test'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKptg2D7OgOE"
      },
      "source": [
        "## Testing (Videos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T05:04:38.616913Z",
          "iopub.status.busy": "2021-10-26T05:04:38.616125Z",
          "iopub.status.idle": "2021-10-26T05:04:38.622595Z",
          "shell.execute_reply": "2021-10-26T05:04:38.621831Z",
          "shell.execute_reply.started": "2021-10-26T05:04:38.616871Z"
        },
        "id": "dgb164SYOgOE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to view video\n",
        "def play(filename):\n",
        "    html = ''\n",
        "    video = open(filename,'rb').read()\n",
        "    src = 'data:video/mp4;base64,' + b64encode(video).decode()\n",
        "    html += '<video width=1000 controls autoplay loop><source src=\"%s\" type=\"video/mp4\"></video>' % src\n",
        "    return HTML(html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T05:04:38.62417Z",
          "iopub.status.busy": "2021-10-26T05:04:38.623887Z",
          "iopub.status.idle": "2021-10-26T05:04:38.633198Z",
          "shell.execute_reply": "2021-10-26T05:04:38.632303Z",
          "shell.execute_reply.started": "2021-10-26T05:04:38.624136Z"
        },
        "id": "Vg1Qf3rJOgOE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Function to process an individual image\n",
        "def process_image(image):\n",
        "    # Preprocess image\n",
        "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    # Get the binary mask\n",
        "    pred_mask = model.predict(np.expand_dims(image, axis = 0))\n",
        "    mask = np.round_(pred_mask[0])\n",
        "\n",
        "    # Convert to mask image\n",
        "    zero_image = np.zeros_like(mask)\n",
        "    mask = np.dstack((mask, zero_image, zero_image)) * 255\n",
        "    mask = np.asarray(mask, np.uint8)\n",
        "\n",
        "    # Get the final image\n",
        "    final_image = weighted_img(mask, image)\n",
        "    final_image = cv2.resize(final_image, (1280, 720))\n",
        "\n",
        "    return final_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T05:04:38.634829Z",
          "iopub.status.busy": "2021-10-26T05:04:38.634551Z",
          "iopub.status.idle": "2021-10-26T05:04:38.643089Z",
          "shell.execute_reply": "2021-10-26T05:04:38.642471Z",
          "shell.execute_reply.started": "2021-10-26T05:04:38.634796Z"
        },
        "id": "hjEId9OfOgOF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Make a new directory\n",
        "os.mkdir(\"videos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwSBRIF0OgOF"
      },
      "source": [
        "### Project Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-10-26T05:04:38.644923Z",
          "iopub.status.busy": "2021-10-26T05:04:38.644661Z",
          "iopub.status.idle": "2021-10-26T05:04:40.920026Z",
          "shell.execute_reply": "2021-10-26T05:04:40.918558Z",
          "shell.execute_reply.started": "2021-10-26T05:04:38.644889Z"
        },
        "id": "7kQ5q6JXOgOF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Creating a VideoCapture object to read the video\n",
        "project_video = \"project_video.mp4\"\n",
        "original_video = cv2.VideoCapture(test_data_dir + project_video)\n",
        "frame_width = int(original_video.get(3))\n",
        "frame_height = int(original_video.get(4))\n",
        "\n",
        "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
        "fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
        "fps = 60\n",
        "output = cv2.VideoWriter(\"videos/\" + project_video, fourcc, fps, (frame_width,frame_height))\n",
        "\n",
        "# Process Video\n",
        "while(original_video.isOpened()):\n",
        "    ret, frame = original_video.read()\n",
        "\n",
        "    if ret == True:\n",
        "        # Write the frame into the file 'output.avi'\n",
        "        output.write(process_image(frame))\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# When everything done, release the video capture and video write objects\n",
        "original_video.release()\n",
        "output.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:40.9214Z",
          "iopub.status.idle": "2021-10-26T05:04:40.921842Z",
          "shell.execute_reply": "2021-10-26T05:04:40.921631Z",
          "shell.execute_reply.started": "2021-10-26T05:04:40.921607Z"
        },
        "id": "fJOuXdqOOgOF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "play(\"videos/\" + project_video)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8SfjzWwOgOF"
      },
      "source": [
        "### Challenge Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:40.923182Z",
          "iopub.status.idle": "2021-10-26T05:04:40.92391Z",
          "shell.execute_reply": "2021-10-26T05:04:40.923691Z",
          "shell.execute_reply.started": "2021-10-26T05:04:40.923663Z"
        },
        "id": "g6-qXnLzOgOI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Creating a VideoCapture object to read the video\n",
        "project_video = \"challenge.mp4\"\n",
        "original_video = cv2.VideoCapture(test_data_dir + project_video)\n",
        "frame_width = int(original_video.get(3))\n",
        "frame_height = int(original_video.get(4))\n",
        "\n",
        "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
        "fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
        "fps = 60\n",
        "output = cv2.VideoWriter(\"videos/\" + project_video, fourcc, fps, (frame_width,frame_height))\n",
        "\n",
        "# Process Video\n",
        "while(original_video.isOpened()):\n",
        "    ret, frame = original_video.read()\n",
        "\n",
        "    if ret == True:\n",
        "        # Write the frame into the file 'output.avi'\n",
        "        output.write(process_image(frame))\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# When everything done, release the video capture and video write objects\n",
        "original_video.release()\n",
        "output.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:40.925135Z",
          "iopub.status.idle": "2021-10-26T05:04:40.925535Z",
          "shell.execute_reply": "2021-10-26T05:04:40.925339Z",
          "shell.execute_reply.started": "2021-10-26T05:04:40.925318Z"
        },
        "id": "8e_afOFGOgOI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "play(\"videos/\" + project_video)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6rY2sOzOgOI"
      },
      "source": [
        "### Challenge Video 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:40.926891Z",
          "iopub.status.idle": "2021-10-26T05:04:40.927455Z",
          "shell.execute_reply": "2021-10-26T05:04:40.927237Z",
          "shell.execute_reply.started": "2021-10-26T05:04:40.927213Z"
        },
        "id": "0rbpDbw7OgOI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Creating a VideoCapture object to read the video\n",
        "project_video = \"challenge_video.mp4\"\n",
        "original_video = cv2.VideoCapture(test_data_dir + project_video)\n",
        "frame_width = int(original_video.get(3))\n",
        "frame_height = int(original_video.get(4))\n",
        "\n",
        "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
        "fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
        "fps = 60\n",
        "output = cv2.VideoWriter(\"videos/\" + project_video, fourcc, fps, (frame_width,frame_height))\n",
        "\n",
        "# Process Video\n",
        "while(original_video.isOpened()):\n",
        "    ret, frame = original_video.read()\n",
        "\n",
        "    if ret == True:\n",
        "        # Write the frame into the file 'output.avi'\n",
        "        output.write(process_image(frame))\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# When everything done, release the video capture and video write objects\n",
        "original_video.release()\n",
        "output.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:40.928721Z",
          "iopub.status.idle": "2021-10-26T05:04:40.929275Z",
          "shell.execute_reply": "2021-10-26T05:04:40.929062Z",
          "shell.execute_reply.started": "2021-10-26T05:04:40.929037Z"
        },
        "id": "xzzUSnr7OgOI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "play(\"videos/\" + project_video)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImaZ9iBJOgOJ"
      },
      "source": [
        "### Harder Challenge Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:40.930547Z",
          "iopub.status.idle": "2021-10-26T05:04:40.931338Z",
          "shell.execute_reply": "2021-10-26T05:04:40.93112Z",
          "shell.execute_reply.started": "2021-10-26T05:04:40.931095Z"
        },
        "id": "zUWDgg0JOgOJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Creating a VideoCapture object to read the video\n",
        "project_video = \"harder_challenge_video.mp4\"\n",
        "original_video = cv2.VideoCapture(test_data_dir + project_video)\n",
        "frame_width = int(original_video.get(3))\n",
        "frame_height = int(original_video.get(4))\n",
        "\n",
        "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
        "fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
        "fps = 60\n",
        "output = cv2.VideoWriter(\"videos/\" + project_video, fourcc, fps, (frame_width,frame_height))\n",
        "\n",
        "\n",
        "while(original_video.isOpened()):\n",
        "    ret, frame = original_video.read()\n",
        "\n",
        "    if ret == True:\n",
        "        # Write the frame into the file 'output.avi'\n",
        "        output.write(process_image(frame))\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# When everything done, release the video capture and video write objects\n",
        "original_video.release()\n",
        "output.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:40.932515Z",
          "iopub.status.idle": "2021-10-26T05:04:40.933315Z",
          "shell.execute_reply": "2021-10-26T05:04:40.933097Z",
          "shell.execute_reply.started": "2021-10-26T05:04:40.933072Z"
        },
        "id": "nOB0l2iPOgOJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "play(\"videos/\" + project_video)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgQanm1UOgOJ"
      },
      "source": [
        "## References\n",
        "\n",
        "- [Kitti Dataset Processing](http://ronny.rest/blog/post_2017_09_06_kitti_road_data/)\n",
        "- [Image Segmentation on Keras](https://yann-leguilly.gitlab.io/post/2019-12-14-tensorflow-tfdata-segmentation/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dTTLxdGOgOJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
